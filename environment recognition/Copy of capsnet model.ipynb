{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"bPWGQF_C0lTB","executionInfo":{"status":"ok","timestamp":1694283100590,"user_tz":-300,"elapsed":393,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W7hXdBwBJGWD","executionInfo":{"status":"ok","timestamp":1694283419808,"user_tz":-300,"elapsed":314997,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}},"outputId":"13413ad5-2356-494f-daf6-4c67ecb8f3b6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import zipfile\n","import os\n","import pandas as pd\n","\n","# Path to the zip file\n","zip_file_path = '/content/drive/MyDrive/environment recognition/places365_contents.zip'\n","\n","# Directory to extract the contents\n","extracted_dir = 'data_contents/'\n","\n","# Extract the contents of the zip file\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    zip_ref.extractall(extracted_dir)\n","\n","# Create a list to store dataframe rows\n","data = []\n","\n","# Traverse through the extracted directory to create the dataframe\n","for root, dirs, files in os.walk(extracted_dir):\n","    for file in files:\n","        if file.endswith('.jpg'):\n","            file_path = os.path.join(root, file)\n","            label_name = os.path.basename(root)\n","            data.append({'path': file_path, 'name': file, 'label': label_name})\n","\n","# Create a DataFrame\n","df = pd.DataFrame(data)\n","\n","# Adjust path format for 'path name' column\n","df['path name'] = 'data_contents/' + df['label'] + '/' + df['name']\n","\n","# Rearrange columns\n","df = df[['path name', 'name', 'label']]\n","\n","# Print the DataFrame\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5M44he1b0rP9","executionInfo":{"status":"ok","timestamp":1694283438387,"user_tz":-300,"elapsed":18583,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}},"outputId":"987a9e02-48b1-4e65-dd36-892bd05172cb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["                                       path name          name           label\n","0      data_contents/airplane_cabin/00002752.jpg  00002752.jpg  airplane_cabin\n","1      data_contents/airplane_cabin/00002732.jpg  00002732.jpg  airplane_cabin\n","2      data_contents/airplane_cabin/00003353.jpg  00003353.jpg  airplane_cabin\n","3      data_contents/airplane_cabin/00002966.jpg  00002966.jpg  airplane_cabin\n","4      data_contents/airplane_cabin/00003053.jpg  00003053.jpg  airplane_cabin\n","...                                          ...           ...             ...\n","62515   data_contents/garage-indoor/00002366.jpg  00002366.jpg   garage-indoor\n","62516   data_contents/garage-indoor/00003245.jpg  00003245.jpg   garage-indoor\n","62517   data_contents/garage-indoor/00004236.jpg  00004236.jpg   garage-indoor\n","62518   data_contents/garage-indoor/00002776.jpg  00002776.jpg   garage-indoor\n","62519   data_contents/garage-indoor/00004939.jpg  00004939.jpg   garage-indoor\n","\n","[62520 rows x 3 columns]\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape\n","from tensorflow.keras.models import Sequential\n","\n","# Define the squash activation function for capsules\n","def squash(x, axis=-1):\n","    norm = tf.norm(x, axis=axis, keepdims=True)\n","    return (norm / (1 + norm**2)) * x\n","\n","# Create the Capsule Layer\n","class CapsuleLayer(tf.keras.layers.Layer):\n","    def __init__(self, num_capsules, capsule_dim, num_routing=3, **kwargs):\n","        super(CapsuleLayer, self).__init__(**kwargs)\n","        self.num_capsules = num_capsules\n","        self.capsule_dim = capsule_dim\n","        self.num_routing = num_routing\n","\n","    def build(self, input_shape):\n","        input_dim = input_shape[-1]\n","        self.kernel = self.add_weight(\n","            'kernel',\n","            shape=[input_dim, self.num_capsules * self.capsule_dim],\n","            initializer='glorot_uniform',\n","            trainable=True\n","        )\n","        super(CapsuleLayer, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        # Transform the input capsules using the weight matrix\n","        inputs = tf.reshape(inputs, [-1, inputs.shape[-1]])\n","        caps_output = tf.matmul(inputs, self.kernel)\n","\n","        # Reshape into capsules\n","        caps_output = tf.reshape(caps_output, [-1, self.num_capsules, self.capsule_dim])\n","\n","        # Dynamic routing algorithm\n","        # Implement the routing algorithm here\n","\n","        # Squash the output capsules\n","        caps_output = squash(caps_output)\n","        return caps_output\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.num_capsules, self.capsule_dim)\n","\n","# Create a simple Capsule Network model\n","def create_capsule_model(input_shape, num_classes):\n","    model = Sequential([\n","        Conv2D(64, (3, 3), padding='valid', input_shape=input_shape, activation='relu'),\n","        Conv2D(128, (3, 3), padding='valid', activation='relu'),\n","        CapsuleLayer(num_capsules=10, capsule_dim=16),  # You can adjust these parameters\n","        Flatten(),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    return model\n","\n","# Define input shape and number of classes\n","input_shape = (112, 112, 3)  # Change this according to your data\n","num_classes = 13  # Change this to the correct number of classes\n","\n","# Create the Capsule Network model\n","model = Sequential([\n","    Conv2D(64, (3, 3), padding='valid', input_shape=input_shape, activation='relu'),\n","    Conv2D(128, (3, 3), padding='valid', activation='relu'),\n","    CapsuleLayer(num_capsules=13, capsule_dim=16),  # Change the number of capsules\n","    Flatten(),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","# Print the model summary\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oX7zvyzJLPue","executionInfo":{"status":"ok","timestamp":1694283678478,"user_tz":-300,"elapsed":1808,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}},"outputId":"f6d50b47-f87c-4f94-bcbb-24a757948815"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 110, 110, 64)      1792      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 108, 108, 128)     73856     \n","                                                                 \n"," capsule_layer (CapsuleLaye  (None, 13, 16)            26624     \n"," r)                                                              \n","                                                                 \n"," flatten (Flatten)           (None, 208)               0         \n","                                                                 \n"," dense (Dense)               (None, 13)                2717      \n","                                                                 \n","=================================================================\n","Total params: 104989 (410.11 KB)\n","Trainable params: 104989 (410.11 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","\n","# Assuming your DataFrame is named 'df'\n","# Split the DataFrame into train and validation sets\n","train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n","\n","# ImageDataGenerator for data augmentation and preprocessing\n","datagen = ImageDataGenerator(\n","    rescale=1.0/255,  # Rescale pixel values to [0, 1]\n","    rotation_range=20,  # Data augmentation: random rotations\n","    width_shift_range=0.2,  # Data augmentation: random width shifts\n","    height_shift_range=0.2,  # Data augmentation: random height shifts\n","    horizontal_flip=True,  # Data augmentation: horizontal flips\n",")\n","batch_size = 32\n","# Load and preprocess training data from DataFrame\n","train_generator = datagen.flow_from_dataframe(\n","    train_df,\n","    x_col='path name',  # Column containing image paths\n","    y_col='label',  # Column containing labels\n","    target_size=(112, 112),  # Resize images to match model input size\n","    batch_size=batch_size,\n","    class_mode='categorical',  # Categorical labels for multi-class classification\n",")\n","\n","# Load and preprocess validation data from DataFrame\n","validation_generator = datagen.flow_from_dataframe(\n","    val_df,\n","    x_col='path name',\n","    y_col='label',\n","    target_size=(112, 112),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GbGXhlQu0ubK","executionInfo":{"status":"ok","timestamp":1694283449310,"user_tz":-300,"elapsed":6710,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}},"outputId":"43eab574-87d4-4ab2-a258-ac28e3d59c18"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 50016 validated image filenames belonging to 13 classes.\n","Found 12504 validated image filenames belonging to 13 classes.\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","\n","model = load_model('/content/drive/MyDrive/environment recognition/capsnet_model_100_epochs.h5')"],"metadata":{"id":"kqSk2syP3DII","executionInfo":{"status":"ok","timestamp":1694283478962,"user_tz":-300,"elapsed":2171,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model on validation data\n","val_loss, val_acc = model.evaluate(validation_generator)\n","\n","print(\"Validation Loss:\", val_loss)\n","print(\"Validation Accuracy:\", val_acc)\n","\n","# # Save the model\n","# model.save('/content/drive/MyDrive/envirnment recognition/model_200_epochs.h5')  # Adjust the filename as needed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0JEzanxn3TJD","executionInfo":{"status":"ok","timestamp":1694283600757,"user_tz":-300,"elapsed":120967,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}},"outputId":"ba0dea49-9f92-42f1-ab71-9e427ea21743"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["391/391 [==============================] - 121s 307ms/step - loss: 11.9517 - accuracy: 0.1508\n","Validation Loss: 11.951667785644531\n","Validation Accuracy: 0.1507517546415329\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OgXaGxDm3cC_"},"execution_count":null,"outputs":[]}]}