{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Fx4518OzLF8x","executionInfo":{"status":"ok","timestamp":1695594651891,"user_tz":-300,"elapsed":438,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ALIX6ECD-zS","executionInfo":{"status":"ok","timestamp":1695594683177,"user_tz":-300,"elapsed":26712,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}},"outputId":"12c340f0-a89a-4d0f-98f7-84f1446ec6cf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22101,"status":"ok","timestamp":1695594712781,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"},"user_tz":-300},"id":"NMilAg50LIiW","outputId":"7afac4e7-45f7-4cea-eaf3-2a88c5f16a0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                      path name          name          label\n","0      data_contents/hospital_room/00004975.jpg  00004975.jpg  hospital_room\n","1      data_contents/hospital_room/00002205.jpg  00002205.jpg  hospital_room\n","2      data_contents/hospital_room/00002331.jpg  00002331.jpg  hospital_room\n","3      data_contents/hospital_room/00004407.jpg  00004407.jpg  hospital_room\n","4      data_contents/hospital_room/00001564.jpg  00001564.jpg  hospital_room\n","...                                         ...           ...            ...\n","62515    data_contents/childs_room/00002942.jpg  00002942.jpg    childs_room\n","62516    data_contents/childs_room/00000819.jpg  00000819.jpg    childs_room\n","62517    data_contents/childs_room/00003682.jpg  00003682.jpg    childs_room\n","62518    data_contents/childs_room/00002129.jpg  00002129.jpg    childs_room\n","62519    data_contents/childs_room/00003051.jpg  00003051.jpg    childs_room\n","\n","[62520 rows x 3 columns]\n"]}],"source":["import zipfile\n","import os\n","import pandas as pd\n","\n","# Path to the zip file\n","zip_file_path = '/content/drive/MyDrive/environment recognition/places365_contents.zip'\n","\n","# Directory to extract the contents\n","extracted_dir = 'data_contents/'\n","\n","# Extract the contents of the zip file\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    zip_ref.extractall(extracted_dir)\n","\n","# Create a list to store dataframe rows\n","data = []\n","\n","# Traverse through the extracted directory to create the dataframe\n","for root, dirs, files in os.walk(extracted_dir):\n","    for file in files:\n","        if file.endswith('.jpg'):\n","            file_path = os.path.join(root, file)\n","            label_name = os.path.basename(root)\n","            data.append({'path': file_path, 'name': file, 'label': label_name})\n","\n","# Create a DataFrame\n","df = pd.DataFrame(data)\n","\n","# Adjust path format for 'path name' column\n","df['path name'] = 'data_contents/' + df['label'] + '/' + df['name']\n","\n","# Rearrange columns\n","df = df[['path name', 'name', 'label']]\n","\n","# Print the DataFrame\n","print(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1694281872513,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"},"user_tz":-300},"id":"TzlgfnzaLnnq","outputId":"a612122d-157f-4a92-fcc0-63161673c107"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["airplane_cabin          5000\n","amusement_arcade        5000\n","childs_room             5000\n","bakery-shop             5000\n","swimming_pool-indoor    5000\n","ballroom                5000\n","locker_room             5000\n","dining_hall             5000\n","hospital_room           5000\n","art_gallery             5000\n","garage-indoor           5000\n","sauna                   4020\n","bank_vault              3500\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":6}],"source":["df['label'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6221,"status":"ok","timestamp":1694281879313,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"},"user_tz":-300},"id":"Daw0a-uJNC2f","outputId":"3b41efbb-dc41-43a8-df67-e70ddd09f458"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 112, 112, 64)      1792      \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 56, 56, 64)        0         \n"," D)                                                              \n","                                                                 \n"," batch_normalization (Batch  (None, 56, 56, 64)        256       \n"," Normalization)                                                  \n","                                                                 \n"," re_lu (ReLU)                (None, 56, 56, 64)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 56, 56, 64)        36928     \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 28, 28, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 28, 28, 64)        256       \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_1 (ReLU)              (None, 28, 28, 64)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 14, 14, 128)       512       \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_2 (ReLU)              (None, 14, 14, 128)       0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 14, 14, 128)       147584    \n","                                                                 \n"," max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)         0         \n"," g2D)                                                            \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 7, 7, 128)         512       \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_3 (ReLU)              (None, 7, 7, 128)         0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 7, 7, 256)         295168    \n","                                                                 \n"," max_pooling2d_4 (MaxPoolin  (None, 3, 3, 256)         0         \n"," g2D)                                                            \n","                                                                 \n"," batch_normalization_4 (Bat  (None, 3, 3, 256)         1024      \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_4 (ReLU)              (None, 3, 3, 256)         0         \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 3, 3, 256)         590080    \n","                                                                 \n"," max_pooling2d_5 (MaxPoolin  (None, 1, 1, 256)         0         \n"," g2D)                                                            \n","                                                                 \n"," batch_normalization_5 (Bat  (None, 1, 1, 256)         1024      \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_5 (ReLU)              (None, 1, 1, 256)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 13)                3341      \n","                                                                 \n","=================================================================\n","Total params: 1152333 (4.40 MB)\n","Trainable params: 1150541 (4.39 MB)\n","Non-trainable params: 1792 (7.00 KB)\n","_________________________________________________________________\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, ReLU, Flatten, Dense\n","from tensorflow.keras.models import Sequential\n","\n","def create_model(input_shape, num_classes):\n","    model = Sequential([\n","        Conv2D(64, (3, 3), padding='same', input_shape=input_shape),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        ReLU(),\n","\n","        Conv2D(64, (3, 3), padding='same'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        ReLU(),\n","\n","        Conv2D(128, (3, 3), padding='same'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        ReLU(),\n","\n","        Conv2D(128, (3, 3), padding='same'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        ReLU(),\n","\n","        Conv2D(256, (3, 3), padding='same'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        ReLU(),\n","\n","        Conv2D(256, (3, 3), padding='same'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        ReLU(),\n","\n","        Flatten(),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    return model\n","\n","# Define input shape and number of classes\n","input_shape = (112, 112, 3)  # Change this according to your data\n","num_classes = 13  # Change this to the correct number of classes\n","\n","# Create the model\n","model = create_model(input_shape, num_classes)\n","\n","# Print the model summary\n","model.summary()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5399,"status":"ok","timestamp":1695594736607,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"},"user_tz":-300},"id":"zG8nI4eeNH-8","outputId":"aea0a900-13ef-4d80-9bde-3b6ad177e785"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 50016 validated image filenames belonging to 13 classes.\n","Found 12504 validated image filenames belonging to 13 classes.\n","{'airplane_cabin': 0, 'amusement_arcade': 1, 'art_gallery': 2, 'bakery-shop': 3, 'ballroom': 4, 'bank_vault': 5, 'childs_room': 6, 'dining_hall': 7, 'garage-indoor': 8, 'hospital_room': 9, 'locker_room': 10, 'sauna': 11, 'swimming_pool-indoor': 12}\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","\n","# Assuming your DataFrame is named 'df'\n","# Split the DataFrame into train and validation sets\n","train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n","\n","# ImageDataGenerator for data augmentation and preprocessing\n","datagen = ImageDataGenerator(\n","    rescale=1.0/255,  # Rescale pixel values to [0, 1]\n","    rotation_range=20,  # Data augmentation: random rotations\n","    width_shift_range=0.2,  # Data augmentation: random width shifts\n","    height_shift_range=0.2,  # Data augmentation: random height shifts\n","    horizontal_flip=True,  # Data augmentation: horizontal flips\n",")\n","batch_size = 32\n","# Load and preprocess training data from DataFrame\n","train_generator = datagen.flow_from_dataframe(\n","    train_df,\n","    x_col='path name',  # Column containing image paths\n","    y_col='label',  # Column containing labels\n","    target_size=(112, 112),  # Resize images to match model input size\n","    batch_size=batch_size,\n","    class_mode='categorical',  # Categorical labels for multi-class classification\n",")\n","\n","# Load and preprocess validation data from DataFrame\n","validation_generator = datagen.flow_from_dataframe(\n","    val_df,\n","    x_col='path name',\n","    y_col='label',\n","    target_size=(112, 112),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n",")\n","label_map = (train_generator.class_indices)\n","print(label_map)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QwxCXjSMpn60"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","\n","model = load_model('/content/drive/MyDrive/environment recognition/model_100_epochs.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJYHVXZP1fGS","outputId":"c990fc70-27e0-407a-ea8b-03400226f71b","executionInfo":{"status":"ok","timestamp":1694282767773,"user_tz":-300,"elapsed":247134,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["391/391 [==============================] - 247s 630ms/step - loss: 0.2665 - accuracy: 0.9202\n","Validation Loss: 0.26654213666915894\n","Validation Accuracy: 0.9201855659484863\n"]}],"source":["# Evaluate the model on validation data\n","val_loss, val_acc = model.evaluate(validation_generator)\n","\n","print(\"Validation Loss:\", val_loss)\n","print(\"Validation Accuracy:\", val_acc)\n","\n","# Save the model\n","#model.save('/content/drive/MyDrive/environment recognition/model_200_epochs.h5')  # Adjust the filename as needed"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}