{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"Fx4518OzLF8x","executionInfo":{"status":"ok","timestamp":1695594282844,"user_tz":-300,"elapsed":658,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"955EXDEozdzh","executionInfo":{"status":"ok","timestamp":1695594305617,"user_tz":-300,"elapsed":21822,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}},"outputId":"e01a7c14-4c32-41ad-ff57-23124c44a5bc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NMilAg50LIiW","outputId":"e8743ffb-8901-4120-f0dd-9ea1a98e70b6","executionInfo":{"status":"ok","timestamp":1695594331626,"user_tz":-300,"elapsed":23623,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["                                    path name          name        label\n","0      data_contents/art_gallery/00000275.jpg  00000275.jpg  art_gallery\n","1      data_contents/art_gallery/00004531.jpg  00004531.jpg  art_gallery\n","2      data_contents/art_gallery/00000609.jpg  00000609.jpg  art_gallery\n","3      data_contents/art_gallery/00003223.jpg  00003223.jpg  art_gallery\n","4      data_contents/art_gallery/00001162.jpg  00001162.jpg  art_gallery\n","...                                       ...           ...          ...\n","62515   data_contents/bank_vault/00000842.jpg  00000842.jpg   bank_vault\n","62516   data_contents/bank_vault/00002841.jpg  00002841.jpg   bank_vault\n","62517   data_contents/bank_vault/00002416.jpg  00002416.jpg   bank_vault\n","62518   data_contents/bank_vault/00001035.jpg  00001035.jpg   bank_vault\n","62519   data_contents/bank_vault/00002327.jpg  00002327.jpg   bank_vault\n","\n","[62520 rows x 3 columns]\n"]}],"source":["import zipfile\n","import os\n","import pandas as pd\n","from google.colab import drive\n","\n","\n","\n","# Path to the zip file\n","zip_file_path = '/content/drive/MyDrive/image classification/places365_contents.zip'\n","\n","# Directory to extract the contents\n","extracted_dir = 'data_contents/'\n","\n","# Extract the contents of the zip file\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    zip_ref.extractall(extracted_dir)\n","\n","# Create a list to store dataframe rows\n","data = []\n","\n","# Traverse through the extracted directory to create the dataframe\n","for root, dirs, files in os.walk(extracted_dir):\n","    for file in files:\n","        if file.endswith('.jpg'):\n","            file_path = os.path.join(root, file)\n","            label_name = os.path.basename(root)\n","            data.append({'path': file_path, 'name': file, 'label': label_name})\n","\n","# Create a DataFrame\n","df = pd.DataFrame(data)\n","\n","# Adjust path format for 'path name' column\n","df['path name'] = 'data_contents/' + df['label'] + '/' + df['name']\n","\n","# Rearrange columns\n","df = df[['path name', 'name', 'label']]\n","\n","# Print the DataFrame\n","print(df)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzlgfnzaLnnq","outputId":"697987da-dbfe-48c7-98bc-1687009c4e91","executionInfo":{"status":"ok","timestamp":1695594346465,"user_tz":-300,"elapsed":438,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["art_gallery             5000\n","hospital_room           5000\n","childs_room             5000\n","airplane_cabin          5000\n","bakery-shop             5000\n","dining_hall             5000\n","amusement_arcade        5000\n","swimming_pool-indoor    5000\n","garage-indoor           5000\n","ballroom                5000\n","locker_room             5000\n","sauna                   4020\n","bank_vault              3500\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":5}],"source":["df['label'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Daw0a-uJNC2f","outputId":"bc9a24c2-3c63-4727-8a07-379e6891e3cc","executionInfo":{"status":"ok","timestamp":1695485513948,"user_tz":-60,"elapsed":6795,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 112, 112, 64)      1792      \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 56, 56, 64)        0         \n"," D)                                                              \n","                                                                 \n"," batch_normalization (Batch  (None, 56, 56, 64)        256       \n"," Normalization)                                                  \n","                                                                 \n"," re_lu (ReLU)                (None, 56, 56, 64)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 56, 56, 64)        36928     \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 28, 28, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 28, 28, 64)        256       \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_1 (ReLU)              (None, 28, 28, 64)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 14, 14, 128)       512       \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_2 (ReLU)              (None, 14, 14, 128)       0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 14, 14, 128)       147584    \n","                                                                 \n"," max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)         0         \n"," g2D)                                                            \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 7, 7, 128)         512       \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_3 (ReLU)              (None, 7, 7, 128)         0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 7, 7, 256)         295168    \n","                                                                 \n"," max_pooling2d_4 (MaxPoolin  (None, 3, 3, 256)         0         \n"," g2D)                                                            \n","                                                                 \n"," batch_normalization_4 (Bat  (None, 3, 3, 256)         1024      \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_4 (ReLU)              (None, 3, 3, 256)         0         \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 3, 3, 256)         590080    \n","                                                                 \n"," max_pooling2d_5 (MaxPoolin  (None, 1, 1, 256)         0         \n"," g2D)                                                            \n","                                                                 \n"," batch_normalization_5 (Bat  (None, 1, 1, 256)         1024      \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_5 (ReLU)              (None, 1, 1, 256)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 13)                3341      \n","                                                                 \n","=================================================================\n","Total params: 1152333 (4.40 MB)\n","Trainable params: 1150541 (4.39 MB)\n","Non-trainable params: 1792 (7.00 KB)\n","_________________________________________________________________\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, ReLU, Flatten, Dense\n","from tensorflow.keras.models import Sequential\n","\n","def create_model(input_shape, num_classes):\n","    model = Sequential([\n","        Conv2D(64, (3, 3), padding='same', input_shape=input_shape),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        ReLU(),\n","\n","        Conv2D(64, (3, 3), padding='same'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        ReLU(),\n","\n","        Conv2D(128, (3, 3), padding='same'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        ReLU(),\n","\n","        Conv2D(128, (3, 3), padding='same'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        ReLU(),\n","\n","        Conv2D(256, (3, 3), padding='same'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        ReLU(),\n","\n","        Conv2D(256, (3, 3), padding='same'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        ReLU(),\n","\n","        Flatten(),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    return model\n","\n","# Define input shape and number of classes\n","input_shape = (112, 112, 3)  # Change this according to your data\n","num_classes = 13  # Change this to the correct number of classes\n","\n","# Create the model\n","model = create_model(input_shape, num_classes)\n","\n","# Print the model summary\n","model.summary()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"zG8nI4eeNH-8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695594615166,"user_tz":-300,"elapsed":633,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}},"outputId":"cf272334-0535-4b2b-f6e8-3288256d2143"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 50016 validated image filenames belonging to 13 classes.\n","Found 12504 validated image filenames belonging to 13 classes.\n","{'airplane_cabin': 0, 'amusement_arcade': 1, 'art_gallery': 2, 'bakery-shop': 3, 'ballroom': 4, 'bank_vault': 5, 'childs_room': 6, 'dining_hall': 7, 'garage-indoor': 8, 'hospital_room': 9, 'locker_room': 10, 'sauna': 11, 'swimming_pool-indoor': 12}\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","\n","# Assuming your DataFrame is named 'df'\n","# Split the DataFrame into train and validation sets\n","train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n","\n","# ImageDataGenerator for data augmentation and preprocessing\n","datagen = ImageDataGenerator(\n","    rescale=1.0/255,  # Rescale pixel values to [0, 1]\n","    rotation_range=20,  # Data augmentation: random rotations\n","    width_shift_range=0.2,  # Data augmentation: random width shifts\n","    height_shift_range=0.2,  # Data augmentation: random height shifts\n","    horizontal_flip=True,  # Data augmentation: horizontal flips\n",")\n","batch_size = 32\n","# Load and preprocess training data from DataFrame\n","train_generator = datagen.flow_from_dataframe(\n","    train_df,\n","    x_col='path name',  # Column containing image paths\n","    y_col='label',  # Column containing labels\n","    target_size=(112, 112),  # Resize images to match model input size\n","    batch_size=batch_size,\n","    class_mode='categorical',  # Categorical labels for multi-class classification\n",")\n","\n","# Load and preprocess validation data from DataFrame\n","validation_generator = datagen.flow_from_dataframe(\n","    val_df,\n","    x_col='path name',\n","    y_col='label',\n","    target_size=(112, 112),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n",")\n","\n","\n","label_map = (train_generator.class_indices)\n","print(label_map)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-A1ELltMpZlz"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q4AGhzLHNPWI"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","\n","# Compile the model\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QwxCXjSMpn60"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","\n","model = load_model('/content/drive/MyDrive/environment recognition/model_100_epochs.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":812},"id":"eVPUJC5zd5G0","outputId":"dc6135cc-648b-42c3-f48f-3970900acdc6","executionInfo":{"status":"error","timestamp":1695488480214,"user_tz":-60,"elapsed":2937843,"user":{"displayName":"roshan humayu","userId":"03021102456355738483"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1563/1563 [==============================] - 343s 211ms/step - loss: 0.3178 - accuracy: 0.9029 - val_loss: 0.3011 - val_accuracy: 0.9054\n","Epoch 2/100\n","1563/1563 [==============================] - 331s 212ms/step - loss: 0.2915 - accuracy: 0.9080 - val_loss: 0.3866 - val_accuracy: 0.8743\n","Epoch 3/100\n","1563/1563 [==============================] - 320s 205ms/step - loss: 0.2800 - accuracy: 0.9093 - val_loss: 0.2811 - val_accuracy: 0.9124\n","Epoch 4/100\n","1563/1563 [==============================] - 321s 206ms/step - loss: 0.2739 - accuracy: 0.9118 - val_loss: 0.3383 - val_accuracy: 0.8928\n","Epoch 5/100\n","1563/1563 [==============================] - 292s 187ms/step - loss: 0.2686 - accuracy: 0.9123 - val_loss: 0.3718 - val_accuracy: 0.8837\n","Epoch 6/100\n","1563/1563 [==============================] - 321s 205ms/step - loss: 0.2665 - accuracy: 0.9136 - val_loss: 0.3908 - val_accuracy: 0.8758\n","Epoch 7/100\n","1563/1563 [==============================] - 291s 186ms/step - loss: 0.2571 - accuracy: 0.9146 - val_loss: 0.3150 - val_accuracy: 0.9003\n","Epoch 8/100\n","1563/1563 [==============================] - 321s 206ms/step - loss: 0.2527 - accuracy: 0.9153 - val_loss: 0.3388 - val_accuracy: 0.8915\n","Epoch 9/100\n","1563/1563 [==============================] - 294s 188ms/step - loss: 0.2491 - accuracy: 0.9184 - val_loss: 0.3463 - val_accuracy: 0.8873\n","Epoch 10/100\n"," 259/1563 [===>..........................] - ETA: 3:13 - loss: 0.2388 - accuracy: 0.9200"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-adb266574930>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Train the model with the callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    862\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from keras.callbacks import ModelCheckpoint\n","import os\n","\n","epochs = 100\n","save_interval = 5  # Save after every epoch\n","model_save_dir = \"/content/drive/MyDrive/environment recognition\"  # Directory to save checkpoints\n","\n","# Create the directory if it doesn't exist\n","os.makedirs(model_save_dir, exist_ok=True)\n","\n","# Define a custom callback class that inherits from ModelCheckpoint\n","class CustomModelCheckpoint(ModelCheckpoint):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if epoch >= 30:  # Start saving from epoch 30\n","            super().on_epoch_end(epoch + 30, logs)\n","#/content/drive/MyDrive/environment recognition/model_30_epochs.h5\n","checkpoint = CustomModelCheckpoint(\n","    filepath=os.path.join(model_save_dir, \"model_epoch{epoch+30:02d}.h5\"),  # Save format\n","    save_best_only=False,\n","    save_weights_only=False,\n","    period=save_interval\n",")\n","\n","# Train the model with the callback\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // batch_size,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // batch_size,\n","    callbacks=[checkpoint]\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i0HbytZJNTUk","outputId":"a055cf79-c5e1-4399-a596-1843fd921107"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","1563/1563 [==============================] - 209s 134ms/step - loss: 0.2128 - accuracy: 0.9275 - val_loss: 0.7799 - val_accuracy: 0.8011\n","Epoch 2/10\n","1563/1563 [==============================] - 211s 135ms/step - loss: 0.2110 - accuracy: 0.9273 - val_loss: 0.6955 - val_accuracy: 0.8171\n","Epoch 3/10\n","1563/1563 [==============================] - 210s 135ms/step - loss: 0.2115 - accuracy: 0.9277 - val_loss: 0.8335 - val_accuracy: 0.7897\n","Epoch 4/10\n","1563/1563 [==============================] - 210s 134ms/step - loss: 0.2126 - accuracy: 0.9268 - val_loss: 0.7351 - val_accuracy: 0.8079\n","Epoch 5/10\n","1563/1563 [==============================] - 207s 133ms/step - loss: 0.2156 - accuracy: 0.9262 - val_loss: 0.7012 - val_accuracy: 0.8189\n","Epoch 6/10\n","1563/1563 [==============================] - 207s 132ms/step - loss: 0.2031 - accuracy: 0.9309 - val_loss: 0.7376 - val_accuracy: 0.8075\n","Epoch 7/10\n","1563/1563 [==============================] - 208s 133ms/step - loss: 0.2097 - accuracy: 0.9274 - val_loss: 0.7095 - val_accuracy: 0.8139\n","Epoch 8/10\n","1563/1563 [==============================] - 208s 133ms/step - loss: 0.2029 - accuracy: 0.9316 - val_loss: 0.7535 - val_accuracy: 0.8118\n","Epoch 9/10\n","1563/1563 [==============================] - 209s 134ms/step - loss: 0.2040 - accuracy: 0.9317 - val_loss: 0.7029 - val_accuracy: 0.8167\n","Epoch 10/10\n","1563/1563 [==============================] - 206s 132ms/step - loss: 0.2032 - accuracy: 0.9306 - val_loss: 0.7147 - val_accuracy: 0.8147\n"]}],"source":["# Train the model\n","epochs = 10  # Adjust as needed\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // batch_size,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // batch_size\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r3nWOpoaNa79"},"outputs":[],"source":["# Evaluate the model on validation data\n","val_loss, val_acc = model.evaluate(validation_generator)\n","\n","print(\"Validation Loss:\", val_loss)\n","print(\"Validation Accuracy:\", val_acc)\n","\n","# Save the model\n","model.save('/content/drive/MyDrive/environment recognition/model_200_epochs.h5')  # Adjust the filename as needed"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wJYHVXZP1fGS","outputId":"33b99823-3817-4296-bb9d-8d0a0869fdb4"},"outputs":[{"name":"stdout","output_type":"stream","text":["391/391 [==============================] - 44s 112ms/step - loss: 0.0371 - accuracy: 0.9876\n","Validation Loss: 0.03714356943964958\n","Validation Accuracy: 0.9876039624214172\n"]}],"source":["# Evaluate the model on validation data\n","val_loss, val_acc = model.evaluate(validation_generator)\n","\n","print(\"Validation Loss:\", val_loss)\n","print(\"Validation Accuracy:\", val_acc)\n","\n","# Save the model\n","model.save('/content/drive/MyDrive/environment recognition/model_200_epochs.h5')  # Adjust the filename as needed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otJ2iNB0MJz9"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}