{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPWGQF_C0lTB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Path to the zip file\n",
        "zip_file_path = '/content/drive/MyDrive/environment recognition/places365_contents.zip'\n",
        "\n",
        "# Directory to extract the contents\n",
        "extracted_dir = 'data_contents/'\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n",
        "# Create a list to store dataframe rows\n",
        "data = []\n",
        "\n",
        "# Traverse through the extracted directory to create the dataframe\n",
        "for root, dirs, files in os.walk(extracted_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            label_name = os.path.basename(root)\n",
        "            data.append({'path': file_path, 'name': file, 'label': label_name})\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Adjust path format for 'path name' column\n",
        "df['path name'] = 'data_contents/' + df['label'] + '/' + df['name']\n",
        "\n",
        "# Rearrange columns\n",
        "df = df[['path name', 'name', 'label']]\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M44he1b0rP9",
        "outputId": "401dfc89-2a5d-44b4-985e-d09e175666d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      path name          name          label\n",
            "0      data_contents/garage-indoor/00003219.jpg  00003219.jpg  garage-indoor\n",
            "1      data_contents/garage-indoor/00000329.jpg  00000329.jpg  garage-indoor\n",
            "2      data_contents/garage-indoor/00003871.jpg  00003871.jpg  garage-indoor\n",
            "3      data_contents/garage-indoor/00001855.jpg  00001855.jpg  garage-indoor\n",
            "4      data_contents/garage-indoor/00000039.jpg  00000039.jpg  garage-indoor\n",
            "...                                         ...           ...            ...\n",
            "62515    data_contents/art_gallery/00001223.jpg  00001223.jpg    art_gallery\n",
            "62516    data_contents/art_gallery/00000348.jpg  00000348.jpg    art_gallery\n",
            "62517    data_contents/art_gallery/00001421.jpg  00001421.jpg    art_gallery\n",
            "62518    data_contents/art_gallery/00003544.jpg  00003544.jpg    art_gallery\n",
            "62519    data_contents/art_gallery/00004748.jpg  00004748.jpg    art_gallery\n",
            "\n",
            "[62520 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your DataFrame is named 'df'\n",
        "# Split the DataFrame into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
        "\n",
        "# ImageDataGenerator for data augmentation and preprocessing\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,  # Rescale pixel values to [0, 1]\n",
        "    rotation_range=20,  # Data augmentation: random rotations\n",
        "    width_shift_range=0.2,  # Data augmentation: random width shifts\n",
        "    height_shift_range=0.2,  # Data augmentation: random height shifts\n",
        "    horizontal_flip=True,  # Data augmentation: horizontal flips\n",
        ")\n",
        "batch_size = 32\n",
        "# Load and preprocess training data from DataFrame\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='path name',  # Column containing image paths\n",
        "    y_col='label',  # Column containing labels\n",
        "    target_size=(112, 112),  # Resize images to match model input size\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Categorical labels for multi-class classification\n",
        ")\n",
        "\n",
        "# Load and preprocess validation data from DataFrame\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col='path name',\n",
        "    y_col='label',\n",
        "    target_size=(112, 112),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbGXhlQu0ubK",
        "outputId": "266a976b-06dd-45a9-8ba1-1f0969e4fb72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 50016 validated image filenames belonging to 13 classes.\n",
            "Found 12504 validated image filenames belonging to 13 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/environment recognition/capsnet_model_100_epochs.h5')"
      ],
      "metadata": {
        "id": "kqSk2syP3DII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on validation data\n",
        "val_loss, val_acc = model.evaluate(validation_generator)\n",
        "\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_acc)\n",
        "\n",
        "# # Save the model\n",
        "# model.save('/content/drive/MyDrive/envirnment recognition/model_200_epochs.h5')  # Adjust the filename as needed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JEzanxn3TJD",
        "outputId": "5040b788-0bee-41fe-c41d-92991f42e2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 135s 343ms/step - loss: 11.9709 - accuracy: 0.1526\n",
            "Validation Loss: 11.970903396606445\n",
            "Validation Accuracy: 0.15259116888046265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OgXaGxDm3cC_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}